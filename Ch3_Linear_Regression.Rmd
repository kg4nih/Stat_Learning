---
title: "Ch3_Linear_Regression"
author: "G Smith"
date: "September 25, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter 3 Linear Regression

My notes and worked examples for linear regression.

```{r}
# Loading my standard work environment libraries and the ISLR library
library(tidyverse)
library(broom)
library(gridExtra)
library(GGally)
library(knitr)
library(ISLR)
```
## 3.6 Lab: Linear Regression

3.6.1 Libraries

```{r}
# ISLR is already laoded
# Loading MASS library
# Note that the MASS library may mess-up the dplry select() function
# I'm also practicing using tibbies, ggplot and the broom packages
library(MASS)
library(dplyr)
# this was a recommended solution; define select to be the dplyr select() function
select <- dplyr::select
rename <- dplyr::rename
```

```{r}
# loading Boston data set
data(Boston)
head(Boston)
attach(Boston)
```
## 3.6.2 Simple Linear Regression

```{r}
# creating first LM and playing w/ making it tidy
lm.fit <- Boston %>% 
  lm(medv~lstat, data = .)
# looking at the broom functions
lm.fit.tidy <- tidy(lm.fit, conf.int = TRUE, conf.level = .95)
lm.fit.tidy
```

```{r}
names(lm.fit.tidy)
```

```{r}
lm.fit.aug <- augment(lm.fit)
lm.fit.aug
```

```{r}
lm.fit.gla <- glance(lm.fit)
lm.fit.gla
```
```{r}
# using the predict() function
# first build a vector of predictor values
lstat.p <- c(1:30)
# run predict() for p_hat and confidence intervals
# the data.frame() is importatant
lm.fit.p_hat <- predict(lm.fit, data.frame(lstat = lstat.p), interval = "confidence")
lm.fit.p_hat
# tidy p_hat and lstat.p by making them into tibbles
lstat.p <- as.tibble(lstat.p)
lm.fit.p_hat <- as.tibble(lm.fit.p_hat)
# place the predictor values in the p_hat tibble and rename value as lstat
lm.fit.p_hat <- bind_cols(lstat.p,lm.fit.p_hat)
lm.fit.p_hat <- lm.fit.p_hat %>% 
  rename(lstat = value, medv = fit)
lm.fit.p_hat
```

```{r}
# plotting the fitted value for medv vs lstat with lower and upper conf intervals
lm.fit.p_hat %>% 
  ggplot(aes(lstat, medv, ymin = lwr, ymax = upr)) +
  geom_errorbar()
```
```{r}
# and now plotting with geom_smooth
lm.fit.p_hat %>% 
  ggplot(aes(lstat, medv, ymin = lwr, ymax = upr)) +
  geom_smooth(method = lm) + 
  geom_errorbar()
```
```{r}
# using ggplot isn't as easy as using the basic abline(lm.fit) call
# some more plottiong using ggplot
# need to get the intercept and slope from lm.fit.tidy
intercept = pull(lm.fit.tidy[1,2])
slope = pull(lm.fit.tidy[2,2])
# plot lstat vs medv and add abline
Boston %>% 
  ggplot(aes(lstat,medv)) +
  geom_point(alpha = 0.5, color = "red") +
  geom_abline(aes(intercept = intercept, slope = slope))
```
```{r}
# plot(predict(lm.fit), residuals(lm.fit)) is more direct
# than using ggplot
pred <- as.tibble(predict(lm.fit))
pred <- pred %>% 
  rename(pred = value)
resid <- as.tibble(residuals(lm.fit))
resid <-  resid %>%
  rename(resid = value)
tab <- bind_cols(pred,resid)
tab %>% 
ggplot(aes(pred, resid)) + 
  geom_point(alpha = 0.5)
```
```{r}
# using the broom augmented results lm.fit.aug
# this is a lot easier than the above!
lm.fit.aug %>% 
  ggplot(aes(.fitted, .resid)) +
  geom_point(alpha = 0.5)
```
```{r}
# plotting .hat (leverage) values and determining the observation w/ the largest leverage
# the challege is defining an index value. My solution is 1:nrow()
max_leverage <- lm.fit.aug %>% filter(.hat == max(.hat))
max_leverage
lm.fit.aug %>% 
  ggplot(aes(1:nrow(lm.fit.aug),.hat)) +
  geom_point(alpha = 0.5) +
  annotate("text", x = 375-50, y = 0.0268517, label = "max leverage",color = "red")
```

## 3.1 Simple Linear Regression
Working thru the examples in the section

```{r}
# load the Advertising data

Advertising <- as.tibble(Advertising)
Advertising
```

```{r}
# some basic data exploration
# first a summary dropping X1 the index
Advertising %>% 
  select(-X1) %>% 
  summary()
```
```{r}
# next pairwise plots
Advertising %>% 
  select(-X1) %>% 
  ggpairs(progress = FALSE)
```
The plot seems to suggest pretty strong relationships between TV and sales, and radio and sales. No so much for newspaper and sales
```{r}
# lm for sales~TV
lm.fit.tv <- Advertising %>% 
                lm(sales~TV, data = .)
summary(lm.fit.tv)
```
```{r}
# tidy, augmnet and glance the model; get the intercept and slope for plotting
lm.fit.tv.tidy <- tidy(lm.fit.tv)
lm.fit.tv.aug <- augment(lm.fit.tv)
lm.fit.tv.aug
lm.fit.tv.gla <- glance(lm.fit.tv)
lm.fit.tv.tidy
intercept <- pull(lm.fit.tv.tidy[1,2])
intercept
slope <- pull(lm.fit.tv.tidy[2,2])
slope
```
```{r}
# plot of sales vs TV w/ regression line
Advertising %>% 
  ggplot(aes(TV, sales)) +
  geom_point(alpha = 0.5, color = "red") +
  geom_abline(aes(intercept = intercept, slope = slope,))
```
Looks like it droops at left end (lower TV value), and has a cone-like spread

```{r}
# an easier way to make the plot above is to use the stat_smooth() function
# it fits a lm (in this case) regression line to the data and adds the regression line w/ a 95% CI
# Here I'm using the augmented tibble
lm.fit.tv.aug %>% 
  ggplot(aes(TV, sales)) +
  geom_point(alpha = 0.5, color = "red") +
  stat_smooth(method = lm, level = 0.95)
```

```{r}
# plot fitted vs residuals
lm.fit.tv.aug %>% 
  ggplot(aes(.fitted, .resid)) +
  geom_point(alpha = 0.5)
```
Confirms that residuals are cone shaped. 
```{r}
# plot of sales vs fitted
lm.fit.tv.aug %>% 
  ggplot(aes(sales, .fitted)) +
  geom_point(alpha = 0.5)
```
```{r}
# looking for high leverage points
lm.fit.tv.aug %>% 
  ggplot(aes(1:nrow(lm.fit.tv.aug),.hat)) +
  geom_point(alpha = 0.5)
```
No apparent high leverage points
```{r}
# calculating r2 by hand just for practice
tss <- sum((Advertising$sales - mean(Advertising$sales))^2)
tss
rss <- sum((lm.fit.tv.aug$sales - lm.fit.tv.aug$.fitted)^2)
rss
r2 <- 1-(rss/tss)
r2
```
## 3.2 Multiple Linear Regression

```{r}
# regressing sales on TV, radio, newspaper
lm.fit.mult <- Advertising %>% 
                lm(sales ~ TV + radio + newspaper, data = .)
summary(lm.fit.mult)
lm.fit.mult.tidy <- tidy(lm.fit.mult, conf.int = TRUE, conf.level = .95)
lm.fit.mult.aug <- augment(lm.fit.mult)
lm.fit.mult.gla <- glance(lm.fit.mult)
lm.fit.mult.tidy
```
```{r}
lm.fit.mult.aug
```

```{r}
lm.fit.mult.gla
```
```{r}
# practising calculating R^2 by hand
names(lm.fit.mult.aug)
tss <- sum((lm.fit.mult.aug$sales - mean(lm.fit.mult.aug$sales))^2)
tss
rss <- sum((lm.fit.mult.aug$sales - lm.fit.mult.aug$.fitted)^2)
rss
r2 <- 1-(rss/tss)
r2
```
## 3.3.1 Qualitative Predictors
```{r}
# loading the Credit data set
data(Credit)
# making the Credit data set a tibble
Credit <- as.tibble(Credit)
Credit
```
```{r}
# running a basic summary of the data
Credit %>% 
  summary()
```
```{r}
# next pairwise plots and correlation
Credit %>% 
  select(-ID) %>% 
  ggpairs(progress = FALSE)
```
```{r}
# a linear regression w/ a qualitative variable w/ 2 levels
lm.fit.gen <- Credit %>% 
  lm(Balance ~ Gender, data =.)
lm.fit.gen.tidy <- tidy(lm.fit.gen, conf.int = TRUE, conf.level = 0.95)
lm.fit.gen.tidy
```
#### There doesn't seem to be a strong relationship between gender and credit card balance. t-stat = 0.4285 w/ p.value = .6685; can't reject the null Ho: B1 = 0
```{r}
# linear regression w/ a qualitative variable w/ 3 levels
# the lm() automatically generates the dummy variables, so no need to create them
lm.fit.eth <- Credit %>% 
  lm(Balance ~ Ethnicity, data = .)
lm.fit.eth.tidy <- tidy(lm.fit.eth, conf.int = TRUE, conf.level = 0.95)
lm.fit.eth.tidy
```
```{r}
# there doesn't appear to be a strong relationship between enthnicity and balace
# using glance() to check the model stats
lm.fit.eth %>% 
  glance()
```
#### very low F-stat = 0.043 and very high p.value. Cannot reject the null hypothesis Ho: B1 = B2 = 0

## 3.3.2 Extensions of the Linear Model

# Removing the Additive Assumption - Interactions
```{r}
# building a model that has an interaction
lm.fit.inter <- Advertising %>% 
                lm(sales ~ TV + radio + TV*radio, data =.)
lm.fit.inter.tidy <- tidy(lm.fit.inter, conf.int = TRUE, conf.level = TRUE)
lm.fit.inter.tidy
```
```{r}
lm.fit.inter.aug <- augment(lm.fit.inter)
lm.fit.inter.aug
```
```{r}
# checking the F-Stat of the model
glance(lm.fit.inter)
```
strong R^2 and very high F-stat. Can reject (fail to accept) the null Ho: B1 = B2 = B3 = 0
```{r}
# a plot of fitted vs residuals
lm.fit.inter.aug %>% 
  ggplot(aes(.fitted, .resid)) +
  geom_point(alpha = 0.5)
```
a little droopy at the left end.
```{r}
# looking for high leverage points
lm.fit.inter.aug %>% 
  ggplot(aes(1:nrow(lm.fit.inter.aug),.hat)) +
  geom_point(alpha = 0.5)
```
looks like one high leverage point; lets find it
```{r}
lm.fit.inter.aug %>% 
  filter(.hat == max(.hat))
```
```{r}
# removing the high leverage point and rerunning the model
lm.fit.inter.2 <- lm.fit.inter.aug %>% 
  filter(.hat != max(.hat)) %>% 
  lm(sales ~ TV + radio + TV*radio, data = .)
glance(lm.fit.inter.2)
```

```{r}
# looking for high leverage points
lm.fit.inter.2.aug <- augment(lm.fit.inter.2)
lm.fit.inter.2.aug %>% 
  ggplot(aes(1:nrow(lm.fit.inter.2.aug),.hat)) +
  geom_point(alpha = 0.5)
```
```{r}
# tidy the model results
tidy(lm.fit.inter.2, conf.int = TRUE, conf.level = 0.95)
```
not a big difference in the model results by removing the high leverage point
```{r}
# fitting a model w/ a quantitatve and qualitative variable
lm.fit.balance.2 <- Credit %>% 
                  lm(Balance ~ Income + Student, data = .)
tidy(lm.fit.balance.2, conf.int = TRUE, conf.level = 0.95)
```
```{r}
# fitting a model w/ a quantitative and qualitative variables and an inreaction
lm.fit.balance.3 <- Credit %>% 
                    lm(Balance ~ Income + Student + Income*Student, data = .)
tidy(lm.fit.balance.3, conf.int = TRUE, conf.level = 0.95)
```

